# This is an example of the config file needed to use the evaluate_llm script
# 3 parameters are needed: 
# - model name
# - name of the API key env variable if the model is API-based 
# - model cache path if the model is to be run locally

- name: llama3-8b-8192
  api_key: GROQ_KEY
  model_cache_path: 

- name: llama3-70b-8192
  api_key: GROQ_KEY
  model_cache_path: 

- name: qwen-qwq-32b
  api_key: GROQ_KEY
  model_cache_path: 

- name: gemma2-9b-it
  api_key: GROQ_KEY
  model_cache_path: 

- name: deepseek-r1-distill-llama-70b
  api_key: GROQ_KEY
  model_cache_path: 

- name: mistral-saba-24b
  api_key: GROQ_KEY
  model_cache_path: 
